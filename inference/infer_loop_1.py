import os
import sys
import time
import torch
import cv2
from torchvision import transforms
from PIL import Image
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from MedViT import MedViT_tiny, MedViT_large  # ho·∫∑c MedViT_tiny n·∫øu b·∫°n d√πng tiny
from ultrasound_dataset import UltrasoundTransform

# === CONFIG ===
checkpoint_path = './MedViT_large_knee2.pth'
model_type = 'MedViT_large'
num_classes = 2
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# === Load m√¥ h√¨nh 1 l·∫ßn duy nh·∫•t ===
print("üîÑ Loading model...")
model = MedViT_large(num_classes=num_classes).to(device)
checkpoint = torch.load(checkpoint_path, map_location=device)
model.load_state_dict(checkpoint['model'], strict=False)
model.eval()
print("‚úÖ Model loaded.")

# === Preprocessing transform ===
transform = UltrasoundTransform(is_training=False)
classes = ['Vi√™m', 'Kh√¥ng vi√™m']

# === V√≤ng l·∫∑p nh·∫≠n ·∫£nh li√™n t·ª•c ===
print("üìÇ Nh·∫≠p ƒë∆∞·ªùng d·∫´n ·∫£nh PNG (ho·∫∑c g√µ 'exit' ƒë·ªÉ tho√°t):")

import cv2
import os

def visualize(image_path, pred_class, confidence):
    # ƒê·ªçc ·∫£nh t·ª´ ƒë∆∞·ªùng d·∫´n
    img = cv2.imread(image_path)
    if img is None:
        raise ValueError(f"Kh√¥ng ƒë·ªçc ƒë∆∞·ª£c ·∫£nh: {image_path}")
    
    output_dir = "./results-normal"
    os.makedirs(output_dir, exist_ok=True)

    # Map class -> label
    class_map = {0: "abnormal", 1: "normal"}
    label = class_map.get(pred_class, str(pred_class))

    # Text hi·ªÉn th·ªã
    text = f"{label} | Conf: {confidence:.2f}"

    # M√†u: ƒë·ªè cho Vi√™m (0), xanh cho Kh√¥ng vi√™m (1)
    color = (0, 0, 255) if pred_class == 0 else (0, 255, 0)

    # V·∫Ω ch·ªØ l√™n ·∫£nh
    cv2.putText(
        img,
        text,
        (30, 50),                      # v·ªã tr√≠ ch·ªØ
        cv2.FONT_HERSHEY_SIMPLEX,      # font
        1,                             # scale
        color,                         # m√†u
        2,                             # ƒë·ªô d√†y
        cv2.LINE_AA
    )

    # L·∫•y basename c·ªßa ·∫£nh g·ªëc
    base = os.path.basename(image_path)
    name, ext = os.path.splitext(base)
    save_path = os.path.join(output_dir, f"{name}_result{ext}")

    # L∆∞u ·∫£nh
    cv2.imwrite(save_path, img)
    print(f"Saved result at {save_path}")
    return img

while True:
    try:
        image_path = input("üñºÔ∏è Path ·∫£nh: ").strip()
        if image_path.lower() == "exit":
            print("üëã K·∫øt th√∫c.")
            break

        if not os.path.isfile(image_path):
            print("‚ùå File kh√¥ng t·ªìn t·∫°i. Th·ª≠ l·∫°i.")
            continue

        # Load v√† transform ·∫£nh
        image = Image.open(image_path).convert('RGB')
        image_tensor = transform(image).unsqueeze(0).to(device)

        # ƒêo th·ªùi gian inference
        start_time = time.perf_counter()
        with torch.no_grad():
            output = model(image_tensor)
            probs = torch.softmax(output, dim=1)
            pred_class = torch.argmax(probs, dim=1).item()
            confidence = probs[0][pred_class].item()
            visualize(image_path, pred_class, confidence)
        end_time = time.perf_counter()

        infer_time = (end_time - start_time) * 1000  # chuy·ªÉn sang ms

        # K·∫øt qu·∫£
        print(f"üîç Prediction: {classes[pred_class]} (confidence: {confidence:.4f})")
        print(f"‚è±Ô∏è Inference time: {infer_time:.2f} ms\n")

    except KeyboardInterrupt:
        print("\nüëã ƒê√£ tho√°t ch∆∞∆°ng tr√¨nh.")
        break
    except Exception as e:
        print(f"‚ö†Ô∏è L·ªói: {e}")
